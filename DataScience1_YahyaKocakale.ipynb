{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f35fc3",
   "metadata": {},
   "source": [
    "### Data Science 1 Assignment Solutions\n",
    "by Yahya Kocakale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f4eb6",
   "metadata": {},
   "source": [
    "#### Q1\n",
    "a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d74d40",
   "metadata": {},
   "source": [
    "While the ridge estimator of $\\beta_{0}$ is as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76eb7c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\beta}_{0}^{ridge} = \\sum \\limits _{i=1} ^{n} Y_{i}/(n+\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002992d",
   "metadata": {},
   "source": [
    "The estimator of $\\beta_{0}$ in case of OLS would be as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18de96",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\beta}_{0} = \\sum \\limits _{i=1} ^{n} Y_{i}/n = \\bar{Y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7de91",
   "metadata": {},
   "source": [
    "While OLS regression with intercept only is equal to mean of dependent variable, ridge estimator would be less than the mean (depends on magnitude of $\\lambda$). While the mean of dependent variable is an unbiased estimator of $Y$, ridge estimator would be a biased estimator of $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81581ff5",
   "metadata": {},
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18ce61f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Predicted_Y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.552025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.474424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105263</td>\n",
       "      <td>1.404213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.157895</td>\n",
       "      <td>1.340385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.210526</td>\n",
       "      <td>1.282108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.263158</td>\n",
       "      <td>1.228687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.315789</td>\n",
       "      <td>1.179539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.368421</td>\n",
       "      <td>1.134172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.421053</td>\n",
       "      <td>1.092166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.473684</td>\n",
       "      <td>1.053160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.526316</td>\n",
       "      <td>1.016844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.578947</td>\n",
       "      <td>0.982949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.631579</td>\n",
       "      <td>0.951241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.684211</td>\n",
       "      <td>0.921515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.736842</td>\n",
       "      <td>0.893590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.789474</td>\n",
       "      <td>0.867308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.842105</td>\n",
       "      <td>0.842528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.894737</td>\n",
       "      <td>0.819124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.947368</td>\n",
       "      <td>0.796986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.776013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lambda  Predicted_Y_hat\n",
       "0    0.000000         1.552025\n",
       "1    1.052632         1.474424\n",
       "2    2.105263         1.404213\n",
       "3    3.157895         1.340385\n",
       "4    4.210526         1.282108\n",
       "5    5.263158         1.228687\n",
       "6    6.315789         1.179539\n",
       "7    7.368421         1.134172\n",
       "8    8.421053         1.092166\n",
       "9    9.473684         1.053160\n",
       "10  10.526316         1.016844\n",
       "11  11.578947         0.982949\n",
       "12  12.631579         0.951241\n",
       "13  13.684211         0.921515\n",
       "14  14.736842         0.893590\n",
       "15  15.789474         0.867308\n",
       "16  16.842105         0.842528\n",
       "17  17.894737         0.819124\n",
       "18  18.947368         0.796986\n",
       "19  20.000000         0.776013"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(20240313)\n",
    "\n",
    "# Define true beta and noise variance\n",
    "beta_0 = 1\n",
    "sigma_sq = 4\n",
    "\n",
    "# Sample size\n",
    "n = 20\n",
    "\n",
    "# Generate random noise\n",
    "noise = np.random.normal(0, np.sqrt(sigma_sq), n)\n",
    "\n",
    "# Generate target variable (Y) with true beta and noise\n",
    "Y = beta_0 + noise\n",
    "\n",
    "# Define grid of lambda values\n",
    "lambda_grid = np.linspace(0, 20, 20)# 100 values from 0 to 20\n",
    "\n",
    "# Iterate through lambda values and compute Ridge estimator\n",
    "predicted_y_hat = []\n",
    "for lambda_val in lambda_grid:\n",
    "    y_hat = Y.sum()/(lambda_val+n)\n",
    "\n",
    "    # Append predicted value to list\n",
    "    predicted_y_hat.append(y_hat)\n",
    "\n",
    "# Create DataFrame with lambda values and predicted Y values\n",
    "result_df = pd.DataFrame({'Lambda': lambda_grid, 'Predicted_Y_hat': predicted_y_hat})\n",
    "\n",
    "# Print the DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe6d0ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.040501816083605"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d75e5c",
   "metadata": {},
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce449e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Lambda  Avg. Bias^2  Avg. Var  Avg. MSE\n",
      "0    0.000000     0.164947  0.200000  0.364947\n",
      "1    1.052632     0.159004  0.158333  0.317338\n",
      "2    2.105263     0.157954  0.131034  0.288989\n",
      "3    3.157895     0.160565  0.111765  0.272330\n",
      "4    4.210526     0.165916  0.097436  0.263352\n",
      "5    5.263158     0.173308  0.086364  0.259672\n",
      "6    6.315789     0.182211  0.077551  0.259762\n",
      "7    7.368421     0.192215  0.070370  0.262586\n",
      "8    8.421053     0.203009  0.064407  0.267416\n",
      "9    9.473684     0.214349  0.059375  0.273724\n",
      "10  10.526316     0.226047  0.055072  0.281119\n",
      "11  11.578947     0.237957  0.051351  0.289308\n",
      "12  12.631579     0.249966  0.048101  0.298067\n",
      "13  13.684211     0.261986  0.045238  0.307224\n",
      "14  14.736842     0.273948  0.042697  0.316645\n",
      "15  15.789474     0.285800  0.040426  0.326226\n",
      "16  16.842105     0.297503  0.038384  0.335887\n",
      "17  17.894737     0.309026  0.036538  0.345564\n",
      "18  18.947368     0.320346  0.034862  0.355208\n",
      "19  20.000000     0.331447  0.033333  0.364780\n"
     ]
    }
   ],
   "source": [
    "# Number of simulations\n",
    "n_simulations = 10\n",
    "\n",
    "# Initialize dictionaries to store results per lambda\n",
    "lambda_results = {}\n",
    "for lambda_val in lambda_grid:\n",
    "  lambda_results[lambda_val] = {\"bias_sq\": [], \"variance\": [], \"mse\": []}\n",
    "\n",
    "for sim_iter in range(n_simulations):\n",
    "\n",
    "  # Generate random noise\n",
    "  noise = np.random.normal(0, np.sqrt(sigma_sq), n)\n",
    "\n",
    "  # Generate target variable (Y) with true beta and noise\n",
    "  Y = beta_0 + noise\n",
    "\n",
    "  for lambda_val in lambda_grid:\n",
    "    # Compute ridge regression estimate manually\n",
    "    y_hat = Y.sum() / (lambda_val + n)\n",
    "\n",
    "    # Analytical variance calculation for ridge with design matrix of ones\n",
    "    var_i = sigma_sq / (n * (1 + lambda_val / sigma_sq))\n",
    "\n",
    "    # Store results for this lambda in the current simulation\n",
    "    lambda_results[lambda_val][\"bias_sq\"].append((beta_0 - y_hat)**2)\n",
    "    lambda_results[lambda_val][\"variance\"].append(var_i)\n",
    "    lambda_results[lambda_val][\"mse\"].append((beta_0 - y_hat)**2 + var_i)\n",
    "\n",
    "# After simulations, calculate averages for each lambda\n",
    "for lambda_val, results in lambda_results.items():\n",
    "  lambda_results[lambda_val][\"bias_sq\"] = np.mean(results[\"bias_sq\"])\n",
    "  lambda_results[lambda_val][\"variance\"] = np.mean(results[\"variance\"])\n",
    "  lambda_results[lambda_val][\"mse\"] = np.mean(results[\"mse\"])\n",
    "\n",
    "# Create DataFrame from results\n",
    "data = {'Lambda': list(lambda_results.keys()), \n",
    "        'Avg. Bias^2': [v[\"bias_sq\"] for v in lambda_results.values()], \n",
    "        'Avg. Var': [v[\"variance\"] for v in lambda_results.values()], \n",
    "        'Avg. MSE': [v[\"mse\"] for v in lambda_results.values()]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f08938",
   "metadata": {},
   "source": [
    "d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "002377cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambda_grid, df['Avg. Bias^2'], label='Avg. Bias^2')\n",
    "plt.plot(lambda_grid, df['Avg. Var'], label='Avg. Var')\n",
    "plt.plot(lambda_grid, df['Avg. MSE'], label='Avg. MSE')\n",
    "plt.xlabel('Lambda ()')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.title('Bias, Variance, and MSE vs. Lambda (Ridge Regression)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bfa0d",
   "metadata": {},
   "source": [
    "The plot shows the trade-off between bias and variance with increasing regularization strength (lambda).\n",
    "\n",
    "* **Bias^2:** Bias^2 increases steadily. As lambda increases, the model becomes more regularized, shrinking the coefficient estimates. This reduces variance but can also introduce bias, causing the predicted beta to deviate from the true beta (beta_0).\n",
    "* **Var:** Initially, variance is high. As lambda increases, the model shrinks the coefficients, reducing the variance of the estimates. This is because the model relies less on specific data points and becomes smoother.\n",
    "* **MSE:** MSE (mean squared error) reflects the overall prediction error. It's the sum of bias^2 and variance. The plot shows a U-shaped curve for MSE. At low lambda, high variance dominates the error. As lambda increases, variance reduces, but bias starts to increase. The optimal lambda value lies somewhere in the middle, where the MSE is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ca427",
   "metadata": {},
   "source": [
    "Ridge regression is a regularization technique that adds a penalty term to the OLS objective function. This penalty term helps to mitigate multicollinearity and overfitting by shrinking the coefficients towards zero. This can be particularly useful when dealing with multicollinear predictors or when the number of predictors is close to or exceeds the number of observations.\n",
    "\n",
    "In situations where multicollinearity is present, ridge regression can often outperform OLS by reducing the variance of the parameter estimates, thus potentially improving prediction accuracy. However, if multicollinearity is not an issue and the linear model assumptions are met, OLS might perform just as well or even better than ridge regression because it provides unbiased estimates of the regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f2c8a2",
   "metadata": {},
   "source": [
    "#### Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912f401",
   "metadata": {},
   "source": [
    "Suppose we estimate the regression coefficients in a linear regression model by minimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d436fe0",
   "metadata": {},
   "source": [
    "$$\n",
    " \\sum_{i=1}^{n}\\left((y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij}) \\right)^2 \\quad \\text{subject to} \\quad \\sum_{j=1}^{p} |\\beta_j| \\leq s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486610aa",
   "metadata": {},
   "source": [
    "for a particular value of s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f448c81",
   "metadata": {},
   "source": [
    "a) As we increase s from 0, the training RSS will: iv) Steadily decrease. This decrease occurs because as s increases, we impose a smaller constraint on the coefficients Betas. Consequently, the coefficients tend to approach their least squares estimates, allowing the model to become more flexible. This increased flexibility leads to a continual decrease in the training RSS (we do not prevent the model to overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf9031",
   "metadata": {},
   "source": [
    "b) As we increase s from 0, the test RSS will ii) Decrease initially, and then eventually start increasing in a U shape. As we gradually increase the value of s from 0, we impose a smaller restriction on the coefficients $\\beta_j$. This flexibility initially results in a decrease in the test residual sum of squares (RSS), followed by an increase, forming a typical U-shaped curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c794abe6",
   "metadata": {},
   "source": [
    "c) As we increase s from 0, variance will iii) Steadily increase As we progressively increase s from 0, we impose a smaller constraint on the coefficients $\\beta_j$. Consequently, the model becomes increasingly flexible, leading to a consistent increase in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a214f2",
   "metadata": {},
   "source": [
    "d) As we increase s from 0, (squared) bias will:  iv) Steadily decrease. Again as s increases from 0, we impose less constraint on the coefficients  $\\beta_j$. Consequently, the model becomes more flexible, resulting in a consistent decrease in bias (we do not prevent the model to overfit, or level of prevention decreases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09816612",
   "metadata": {},
   "source": [
    "e) As we increase s from 0, irreducible error: v) Remain constant. The irreducible error is the noise or randomness in data generating process error and remains unaffected by the model (actually cannot be modeled), and therefore, it remains unaffected by the value of s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68029094",
   "metadata": {},
   "source": [
    "#### Q3)\n",
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dec7d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete sample shape: (1000, 51)\n",
      "Training sample shape: (500, 51)\n",
      "Testing sample shape: (500, 51)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/kocakale/hello-world/master/PCA_data.csv\")\n",
    "\n",
    "print(\"Complete sample shape:\", data.shape)\n",
    "\n",
    "# Extract the training and testing samples\n",
    "train_data = data.iloc[:500]\n",
    "test_data = data.iloc[-500:]\n",
    "\n",
    "print(\"Training sample shape:\", train_data.shape)\n",
    "print(\"Testing sample shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8ff63b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.539179</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>1.259177</td>\n",
       "      <td>0.763472</td>\n",
       "      <td>0.128735</td>\n",
       "      <td>0.410222</td>\n",
       "      <td>0.420989</td>\n",
       "      <td>-0.101123</td>\n",
       "      <td>-1.242581</td>\n",
       "      <td>0.029933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859282</td>\n",
       "      <td>-1.645036</td>\n",
       "      <td>-0.247500</td>\n",
       "      <td>1.372374</td>\n",
       "      <td>-0.212618</td>\n",
       "      <td>-1.368046</td>\n",
       "      <td>-1.740719</td>\n",
       "      <td>0.925212</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>-1.020763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.036508</td>\n",
       "      <td>0.019661</td>\n",
       "      <td>-1.951131</td>\n",
       "      <td>-1.097787</td>\n",
       "      <td>0.919061</td>\n",
       "      <td>-0.069719</td>\n",
       "      <td>0.405042</td>\n",
       "      <td>1.808955</td>\n",
       "      <td>-0.343013</td>\n",
       "      <td>1.465924</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.809128</td>\n",
       "      <td>0.381091</td>\n",
       "      <td>0.497534</td>\n",
       "      <td>0.632532</td>\n",
       "      <td>-1.429868</td>\n",
       "      <td>-2.092106</td>\n",
       "      <td>0.499216</td>\n",
       "      <td>1.026407</td>\n",
       "      <td>-0.763639</td>\n",
       "      <td>-0.405548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.295433</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>1.127620</td>\n",
       "      <td>1.458154</td>\n",
       "      <td>0.227844</td>\n",
       "      <td>-2.003859</td>\n",
       "      <td>-1.775359</td>\n",
       "      <td>-2.480777</td>\n",
       "      <td>0.506680</td>\n",
       "      <td>0.852822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091664</td>\n",
       "      <td>0.655664</td>\n",
       "      <td>-0.191965</td>\n",
       "      <td>1.194055</td>\n",
       "      <td>0.326962</td>\n",
       "      <td>0.399151</td>\n",
       "      <td>0.723069</td>\n",
       "      <td>0.939017</td>\n",
       "      <td>-1.132469</td>\n",
       "      <td>0.212292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.825405</td>\n",
       "      <td>0.845641</td>\n",
       "      <td>-0.921489</td>\n",
       "      <td>-1.368601</td>\n",
       "      <td>2.085195</td>\n",
       "      <td>-0.294420</td>\n",
       "      <td>1.029018</td>\n",
       "      <td>0.098418</td>\n",
       "      <td>-0.677591</td>\n",
       "      <td>-1.276767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280935</td>\n",
       "      <td>-0.523440</td>\n",
       "      <td>-0.230028</td>\n",
       "      <td>1.939640</td>\n",
       "      <td>-0.429125</td>\n",
       "      <td>0.701319</td>\n",
       "      <td>-1.008541</td>\n",
       "      <td>1.055334</td>\n",
       "      <td>-0.782659</td>\n",
       "      <td>0.749695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.176432</td>\n",
       "      <td>0.566670</td>\n",
       "      <td>0.667277</td>\n",
       "      <td>-0.248455</td>\n",
       "      <td>1.361258</td>\n",
       "      <td>0.041326</td>\n",
       "      <td>0.149155</td>\n",
       "      <td>-0.271543</td>\n",
       "      <td>0.229179</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728898</td>\n",
       "      <td>-0.124473</td>\n",
       "      <td>-0.842829</td>\n",
       "      <td>-0.132558</td>\n",
       "      <td>-0.236122</td>\n",
       "      <td>-0.751535</td>\n",
       "      <td>0.191009</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>-0.350858</td>\n",
       "      <td>0.384321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y        X1        X2        X3        X4        X5        X6  \\\n",
       "0 -6.539179  0.948014  1.259177  0.763472  0.128735  0.410222  0.420989   \n",
       "1  2.036508  0.019661 -1.951131 -1.097787  0.919061 -0.069719  0.405042   \n",
       "2  7.295433  0.283019  1.127620  1.458154  0.227844 -2.003859 -1.775359   \n",
       "3  6.825405  0.845641 -0.921489 -1.368601  2.085195 -0.294420  1.029018   \n",
       "4 -0.176432  0.566670  0.667277 -0.248455  1.361258  0.041326  0.149155   \n",
       "\n",
       "         X7        X8        X9  ...       X41       X42       X43       X44  \\\n",
       "0 -0.101123 -1.242581  0.029933  ... -0.859282 -1.645036 -0.247500  1.372374   \n",
       "1  1.808955 -0.343013  1.465924  ... -1.809128  0.381091  0.497534  0.632532   \n",
       "2 -2.480777  0.506680  0.852822  ...  0.091664  0.655664 -0.191965  1.194055   \n",
       "3  0.098418 -0.677591 -1.276767  ... -0.280935 -0.523440 -0.230028  1.939640   \n",
       "4 -0.271543  0.229179  0.089760  ... -0.728898 -0.124473 -0.842829 -0.132558   \n",
       "\n",
       "        X45       X46       X47       X48       X49       X50  \n",
       "0 -0.212618 -1.368046 -1.740719  0.925212  0.123907 -1.020763  \n",
       "1 -1.429868 -2.092106  0.499216  1.026407 -0.763639 -0.405548  \n",
       "2  0.326962  0.399151  0.723069  0.939017 -1.132469  0.212292  \n",
       "3 -0.429125  0.701319 -1.008541  1.055334 -0.782659  0.749695  \n",
       "4 -0.236122 -0.751535  0.191009  0.007180 -0.350858  0.384321  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5b6585",
   "metadata": {},
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4829059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of principal component vectors: (10, 50)\n",
      "Shape of principal component scores: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Selecting only the columns from the second column onwards\n",
    "data_for_pca = data.iloc[:, 1:]\n",
    "\n",
    "# Perform PCA on the selected dataset\n",
    "pca = PCA(n_components=10)  # Set number of components to 10\n",
    "pca.fit(data_for_pca)\n",
    "\n",
    "# Compute the principal component vectors\n",
    "principal_components = pca.components_\n",
    "\n",
    "# Compute the principal component scores for the entire dataset\n",
    "principal_component_scores = pca.transform(data_for_pca )\n",
    "\n",
    "# Print the shapes of the principal component vectors and scores\n",
    "print(\"Shape of principal component vectors:\", principal_components.shape)\n",
    "print(\"Shape of principal component scores:\", principal_component_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "876e2b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.098020</td>\n",
       "      <td>-0.269744</td>\n",
       "      <td>0.181046</td>\n",
       "      <td>0.246482</td>\n",
       "      <td>0.282823</td>\n",
       "      <td>0.198562</td>\n",
       "      <td>-0.085632</td>\n",
       "      <td>-0.140379</td>\n",
       "      <td>0.132491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>-0.079063</td>\n",
       "      <td>0.126562</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>-0.220344</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>0.170688</td>\n",
       "      <td>0.148155</td>\n",
       "      <td>-0.074001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.381373</td>\n",
       "      <td>-0.150502</td>\n",
       "      <td>-0.218536</td>\n",
       "      <td>-0.225906</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>-0.096144</td>\n",
       "      <td>0.169221</td>\n",
       "      <td>0.284435</td>\n",
       "      <td>-0.034900</td>\n",
       "      <td>-0.159718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101879</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.014569</td>\n",
       "      <td>-0.028299</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.068511</td>\n",
       "      <td>0.048711</td>\n",
       "      <td>-0.058445</td>\n",
       "      <td>-0.033570</td>\n",
       "      <td>0.061780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135455</td>\n",
       "      <td>-0.151683</td>\n",
       "      <td>0.091704</td>\n",
       "      <td>-0.265128</td>\n",
       "      <td>-0.023357</td>\n",
       "      <td>0.273531</td>\n",
       "      <td>-0.015595</td>\n",
       "      <td>-0.225426</td>\n",
       "      <td>-0.336526</td>\n",
       "      <td>-0.240375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124930</td>\n",
       "      <td>-0.082045</td>\n",
       "      <td>0.150568</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>0.068967</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.050563</td>\n",
       "      <td>-0.014486</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072821</td>\n",
       "      <td>0.363308</td>\n",
       "      <td>0.142877</td>\n",
       "      <td>0.047319</td>\n",
       "      <td>0.066819</td>\n",
       "      <td>0.028402</td>\n",
       "      <td>-0.136384</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>-0.223713</td>\n",
       "      <td>-0.036722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074048</td>\n",
       "      <td>0.121794</td>\n",
       "      <td>0.118764</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.191967</td>\n",
       "      <td>-0.072060</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.128408</td>\n",
       "      <td>-0.061159</td>\n",
       "      <td>0.136403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>0.106002</td>\n",
       "      <td>-0.179083</td>\n",
       "      <td>0.137090</td>\n",
       "      <td>0.059248</td>\n",
       "      <td>0.248162</td>\n",
       "      <td>-0.102069</td>\n",
       "      <td>0.116152</td>\n",
       "      <td>0.154060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117559</td>\n",
       "      <td>-0.166363</td>\n",
       "      <td>0.045958</td>\n",
       "      <td>-0.265675</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>-0.214856</td>\n",
       "      <td>-0.104622</td>\n",
       "      <td>0.077517</td>\n",
       "      <td>-0.003688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.122263</td>\n",
       "      <td>0.031870</td>\n",
       "      <td>-0.147917</td>\n",
       "      <td>0.064602</td>\n",
       "      <td>0.183527</td>\n",
       "      <td>-0.042450</td>\n",
       "      <td>0.200205</td>\n",
       "      <td>0.110942</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.244227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300020</td>\n",
       "      <td>0.311073</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.042557</td>\n",
       "      <td>-0.010351</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.152032</td>\n",
       "      <td>-0.034547</td>\n",
       "      <td>-0.088280</td>\n",
       "      <td>0.212683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008255</td>\n",
       "      <td>-0.118745</td>\n",
       "      <td>0.086215</td>\n",
       "      <td>-0.019012</td>\n",
       "      <td>-0.208943</td>\n",
       "      <td>-0.077977</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.096511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027766</td>\n",
       "      <td>0.201443</td>\n",
       "      <td>-0.121948</td>\n",
       "      <td>-0.139761</td>\n",
       "      <td>0.226457</td>\n",
       "      <td>-0.205531</td>\n",
       "      <td>-0.040311</td>\n",
       "      <td>0.278004</td>\n",
       "      <td>-0.058872</td>\n",
       "      <td>0.072655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.088624</td>\n",
       "      <td>0.064691</td>\n",
       "      <td>0.083605</td>\n",
       "      <td>-0.028516</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.159380</td>\n",
       "      <td>-0.046206</td>\n",
       "      <td>-0.011259</td>\n",
       "      <td>0.056364</td>\n",
       "      <td>-0.059896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038541</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.003525</td>\n",
       "      <td>-0.251139</td>\n",
       "      <td>0.137805</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>-0.240099</td>\n",
       "      <td>0.057159</td>\n",
       "      <td>0.083136</td>\n",
       "      <td>0.032090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.004524</td>\n",
       "      <td>0.127439</td>\n",
       "      <td>0.079970</td>\n",
       "      <td>-0.071861</td>\n",
       "      <td>0.046680</td>\n",
       "      <td>-0.057785</td>\n",
       "      <td>-0.074370</td>\n",
       "      <td>-0.058453</td>\n",
       "      <td>0.163148</td>\n",
       "      <td>-0.168188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078800</td>\n",
       "      <td>-0.079654</td>\n",
       "      <td>-0.142207</td>\n",
       "      <td>0.112399</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>-0.105597</td>\n",
       "      <td>0.087726</td>\n",
       "      <td>-0.066638</td>\n",
       "      <td>-0.144544</td>\n",
       "      <td>0.120043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.035516</td>\n",
       "      <td>-0.042228</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>-0.026768</td>\n",
       "      <td>-0.048207</td>\n",
       "      <td>-0.058648</td>\n",
       "      <td>0.201471</td>\n",
       "      <td>-0.042331</td>\n",
       "      <td>0.068509</td>\n",
       "      <td>0.042266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230127</td>\n",
       "      <td>-0.029314</td>\n",
       "      <td>-0.264977</td>\n",
       "      <td>-0.080253</td>\n",
       "      <td>0.189824</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.074382</td>\n",
       "      <td>-0.093982</td>\n",
       "      <td>-0.115178</td>\n",
       "      <td>-0.179345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.027387 -0.098020 -0.269744  0.181046  0.246482  0.282823  0.198562   \n",
       "1 -0.381373 -0.150502 -0.218536 -0.225906  0.246900 -0.096144  0.169221   \n",
       "2  0.135455 -0.151683  0.091704 -0.265128 -0.023357  0.273531 -0.015595   \n",
       "3  0.072821  0.363308  0.142877  0.047319  0.066819  0.028402 -0.136384   \n",
       "4  0.007024  0.058495  0.106002 -0.179083  0.137090  0.059248  0.248162   \n",
       "5 -0.122263  0.031870 -0.147917  0.064602  0.183527 -0.042450  0.200205   \n",
       "6  0.008255 -0.118745  0.086215 -0.019012 -0.208943 -0.077977  0.015355   \n",
       "7  0.088624  0.064691  0.083605 -0.028516  0.010950  0.159380 -0.046206   \n",
       "8 -0.004524  0.127439  0.079970 -0.071861  0.046680 -0.057785 -0.074370   \n",
       "9  0.035516 -0.042228  0.078200 -0.026768 -0.048207 -0.058648  0.201471   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0 -0.085632 -0.140379  0.132491  ...  0.065853 -0.019035 -0.079063  0.126562   \n",
       "1  0.284435 -0.034900 -0.159718  ...  0.101879  0.000302 -0.014569 -0.028299   \n",
       "2 -0.225426 -0.336526 -0.240375  ... -0.124930 -0.082045  0.150568  0.038968   \n",
       "3  0.018643 -0.223713 -0.036722  ...  0.074048  0.121794  0.118764  0.043430   \n",
       "4 -0.102069  0.116152  0.154060  ... -0.117559 -0.166363  0.045958 -0.265675   \n",
       "5  0.110942  0.032981  0.244227  ... -0.300020  0.311073  0.027125  0.042557   \n",
       "6  0.061867  0.042029  0.096511  ...  0.027766  0.201443 -0.121948 -0.139761   \n",
       "7 -0.011259  0.056364 -0.059896  ... -0.038541 -0.053670 -0.003525 -0.251139   \n",
       "8 -0.058453  0.163148 -0.168188  ... -0.078800 -0.079654 -0.142207  0.112399   \n",
       "9 -0.042331  0.068509  0.042266  ...  0.230127 -0.029314 -0.264977 -0.080253   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0  0.037256 -0.220344  0.082252  0.170688  0.148155 -0.074001  \n",
       "1  0.022736  0.068511  0.048711 -0.058445 -0.033570  0.061780  \n",
       "2  0.068967  0.018210  0.026861  0.050563 -0.014486  0.022800  \n",
       "3  0.191967 -0.072060 -0.043032 -0.128408 -0.061159  0.136403  \n",
       "4 -0.011809  0.037926 -0.214856 -0.104622  0.077517 -0.003688  \n",
       "5 -0.010351  0.052265  0.152032 -0.034547 -0.088280  0.212683  \n",
       "6  0.226457 -0.205531 -0.040311  0.278004 -0.058872  0.072655  \n",
       "7  0.137805  0.073288 -0.240099  0.057159  0.083136  0.032090  \n",
       "8  0.199707 -0.105597  0.087726 -0.066638 -0.144544  0.120043  \n",
       "9  0.189824  0.014096  0.074382 -0.093982 -0.115178 -0.179345  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a88499b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.550957</td>\n",
       "      <td>-2.970281</td>\n",
       "      <td>0.266931</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>1.976533</td>\n",
       "      <td>-1.986773</td>\n",
       "      <td>-0.618811</td>\n",
       "      <td>-1.886173</td>\n",
       "      <td>1.267789</td>\n",
       "      <td>-1.055589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.796632</td>\n",
       "      <td>-2.478406</td>\n",
       "      <td>-0.537754</td>\n",
       "      <td>-4.003418</td>\n",
       "      <td>1.002937</td>\n",
       "      <td>1.761132</td>\n",
       "      <td>1.315558</td>\n",
       "      <td>-2.160971</td>\n",
       "      <td>-0.367547</td>\n",
       "      <td>-0.713611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.258702</td>\n",
       "      <td>-2.646898</td>\n",
       "      <td>0.101036</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>-5.052483</td>\n",
       "      <td>1.808161</td>\n",
       "      <td>0.567196</td>\n",
       "      <td>1.009530</td>\n",
       "      <td>0.343479</td>\n",
       "      <td>0.216567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.640444</td>\n",
       "      <td>-2.964102</td>\n",
       "      <td>0.645759</td>\n",
       "      <td>-0.164768</td>\n",
       "      <td>-2.899882</td>\n",
       "      <td>1.728583</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>-0.360779</td>\n",
       "      <td>-1.430756</td>\n",
       "      <td>1.046878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.588698</td>\n",
       "      <td>-1.423326</td>\n",
       "      <td>-1.484493</td>\n",
       "      <td>0.391902</td>\n",
       "      <td>-1.639247</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>-0.635212</td>\n",
       "      <td>1.146812</td>\n",
       "      <td>-0.610385</td>\n",
       "      <td>0.757825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-5.271244</td>\n",
       "      <td>-1.862333</td>\n",
       "      <td>1.395786</td>\n",
       "      <td>1.796356</td>\n",
       "      <td>-0.152609</td>\n",
       "      <td>-1.018832</td>\n",
       "      <td>1.416505</td>\n",
       "      <td>0.175896</td>\n",
       "      <td>0.366758</td>\n",
       "      <td>1.966468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.419875</td>\n",
       "      <td>1.342245</td>\n",
       "      <td>2.643950</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>-2.925716</td>\n",
       "      <td>1.377737</td>\n",
       "      <td>-2.404207</td>\n",
       "      <td>0.248670</td>\n",
       "      <td>-1.223590</td>\n",
       "      <td>-1.437680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.838082</td>\n",
       "      <td>4.706940</td>\n",
       "      <td>1.036514</td>\n",
       "      <td>1.926721</td>\n",
       "      <td>-1.571925</td>\n",
       "      <td>-0.500653</td>\n",
       "      <td>3.292465</td>\n",
       "      <td>-0.967919</td>\n",
       "      <td>-2.120489</td>\n",
       "      <td>-0.768788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.859131</td>\n",
       "      <td>-0.015351</td>\n",
       "      <td>0.881794</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.438718</td>\n",
       "      <td>-1.541520</td>\n",
       "      <td>0.762893</td>\n",
       "      <td>-3.618981</td>\n",
       "      <td>2.574746</td>\n",
       "      <td>1.067443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.470580</td>\n",
       "      <td>-2.167069</td>\n",
       "      <td>1.520015</td>\n",
       "      <td>0.976286</td>\n",
       "      <td>5.594855</td>\n",
       "      <td>3.910117</td>\n",
       "      <td>-0.874431</td>\n",
       "      <td>-0.359908</td>\n",
       "      <td>-0.074289</td>\n",
       "      <td>1.349854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.550957 -2.970281  0.266931  0.174905  1.976533 -1.986773 -0.618811   \n",
       "1    2.796632 -2.478406 -0.537754 -4.003418  1.002937  1.761132  1.315558   \n",
       "2   -4.258702 -2.646898  0.101036  0.671717 -5.052483  1.808161  0.567196   \n",
       "3    2.640444 -2.964102  0.645759 -0.164768 -2.899882  1.728583 -0.551543   \n",
       "4    0.588698 -1.423326 -1.484493  0.391902 -1.639247  0.555400 -0.635212   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -5.271244 -1.862333  1.395786  1.796356 -0.152609 -1.018832  1.416505   \n",
       "996  1.419875  1.342245  2.643950  0.308932 -2.925716  1.377737 -2.404207   \n",
       "997 -0.838082  4.706940  1.036514  1.926721 -1.571925 -0.500653  3.292465   \n",
       "998  0.859131 -0.015351  0.881794  0.193029  0.438718 -1.541520  0.762893   \n",
       "999 -0.470580 -2.167069  1.520015  0.976286  5.594855  3.910117 -0.874431   \n",
       "\n",
       "            7         8         9  \n",
       "0   -1.886173  1.267789 -1.055589  \n",
       "1   -2.160971 -0.367547 -0.713611  \n",
       "2    1.009530  0.343479  0.216567  \n",
       "3   -0.360779 -1.430756  1.046878  \n",
       "4    1.146812 -0.610385  0.757825  \n",
       "..        ...       ...       ...  \n",
       "995  0.175896  0.366758  1.966468  \n",
       "996  0.248670 -1.223590 -1.437680  \n",
       "997 -0.967919 -2.120489 -0.768788  \n",
       "998 -3.618981  2.574746  1.067443  \n",
       "999 -0.359908 -0.074289  1.349854  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(principal_component_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1c735",
   "metadata": {},
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a87b63ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.759\n",
      "Model:                            OLS   Adj. R-squared:                  0.732\n",
      "Method:                 Least Squares   F-statistic:                     28.25\n",
      "Date:                Fri, 15 Mar 2024   Prob (F-statistic):          4.65e-109\n",
      "Time:                        00:27:12   Log-Likelihood:                -1028.1\n",
      "No. Observations:                 500   AIC:                             2158.\n",
      "Df Residuals:                     449   BIC:                             2373.\n",
      "Df Model:                          50                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9368      0.093     10.104      0.000       0.755       1.119\n",
      "X1         -2.515e+04   2.21e+04     -1.141      0.255   -6.85e+04    1.82e+04\n",
      "X2         -2.054e+05   1.95e+05     -1.051      0.294    -5.9e+05    1.79e+05\n",
      "X3          2.802e+05   2.66e+05      1.054      0.292   -2.42e+05    8.02e+05\n",
      "X4           1.21e+05   1.14e+05      1.065      0.288   -1.02e+05    3.44e+05\n",
      "X5          2.364e+05   2.25e+05      1.050      0.294   -2.06e+05    6.79e+05\n",
      "X6         -3.223e+04   3.12e+04     -1.032      0.303   -9.36e+04    2.91e+04\n",
      "X7         -8.144e+04   7.76e+04     -1.050      0.294   -2.34e+05     7.1e+04\n",
      "X8          3.664e+04   3.59e+04      1.021      0.308   -3.39e+04    1.07e+05\n",
      "X9         -2.415e+04   2.31e+04     -1.046      0.296   -6.95e+04    2.12e+04\n",
      "X10         1.756e+04   1.67e+04      1.055      0.292   -1.52e+04    5.03e+04\n",
      "X11          2.36e+04   2.33e+04      1.012      0.312   -2.22e+04    6.94e+04\n",
      "X12        -6477.9263   6077.053     -1.066      0.287   -1.84e+04    5465.072\n",
      "X13        -1.155e+04   1.14e+04     -1.012      0.312    -3.4e+04    1.09e+04\n",
      "X14        -1011.4583    919.988     -1.099      0.272   -2819.475     796.559\n",
      "X15         -643.7750    474.650     -1.356      0.176   -1576.587     289.037\n",
      "X16        -1487.2221   1802.983     -0.825      0.410   -5030.555    2056.111\n",
      "X17         3405.3863   3153.266      1.080      0.281   -2791.605    9602.377\n",
      "X18        -1211.3943   1181.874     -1.025      0.306   -3534.086    1111.297\n",
      "X19         1505.9101   1609.371      0.936      0.350   -1656.924    4668.744\n",
      "X20         2634.1673   2526.070      1.043      0.298   -2330.220    7598.555\n",
      "X21          359.3366    326.098      1.102      0.271    -281.531    1000.204\n",
      "X22         1769.9189   1652.235      1.071      0.285   -1477.155    5016.993\n",
      "X23          296.9050    354.750      0.837      0.403    -400.272     994.082\n",
      "X24         -292.2016    234.719     -1.245      0.214    -753.486     169.083\n",
      "X25          846.7998    812.801      1.042      0.298    -750.567    2444.166\n",
      "X26         -504.4524    438.077     -1.152      0.250   -1365.388     356.483\n",
      "X27         -219.6599    222.678     -0.986      0.324    -657.280     217.961\n",
      "X28          115.8915    114.025      1.016      0.310    -108.198     339.981\n",
      "X29         -172.3402    139.150     -1.239      0.216    -445.806     101.126\n",
      "X30          -92.9268     91.451     -1.016      0.310    -272.652      86.799\n",
      "X31          -68.4752     64.775     -1.057      0.291    -195.775      58.824\n",
      "X32           57.0299     42.849      1.331      0.184     -27.180     141.239\n",
      "X33           32.7774     27.686      1.184      0.237     -21.632      87.187\n",
      "X34           -3.9460      8.189     -0.482      0.630     -20.040      12.148\n",
      "X35            4.9526     10.552      0.469      0.639     -15.786      25.691\n",
      "X36           13.8703     15.006      0.924      0.356     -15.620      43.361\n",
      "X37            2.4123      7.149      0.337      0.736     -11.637      16.462\n",
      "X38           19.6961     17.365      1.134      0.257     -14.431      53.823\n",
      "X39            2.0582      4.915      0.419      0.676      -7.601      11.717\n",
      "X40            4.8008      3.616      1.328      0.185      -2.306      11.908\n",
      "X41           11.8244      9.419      1.255      0.210      -6.687      30.336\n",
      "X42           -1.7913      2.264     -0.791      0.429      -6.241       2.658\n",
      "X43            7.4995      5.002      1.499      0.135      -2.331      17.330\n",
      "X44            9.5782      6.813      1.406      0.160      -3.810      22.967\n",
      "X45           -2.7872      3.442     -0.810      0.418      -9.551       3.977\n",
      "X46           -2.2377      1.772     -1.263      0.207      -5.720       1.244\n",
      "X47           -0.5843      1.084     -0.539      0.590      -2.715       1.547\n",
      "X48           -0.3489      1.116     -0.313      0.755      -2.543       1.845\n",
      "X49            1.1468      0.621      1.848      0.065      -0.073       2.366\n",
      "X50            1.0205      0.572      1.785      0.075      -0.103       2.144\n",
      "==============================================================================\n",
      "Omnibus:                        2.161   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.339   Jarque-Bera (JB):                2.037\n",
      "Skew:                           0.085   Prob(JB):                        0.361\n",
      "Kurtosis:                       2.737   Cond. No.                     1.15e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.18e-11. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variables (including the constant)\n",
    "X_train = sm.add_constant(train_data.drop(columns=['Y']))\n",
    "\n",
    "# Define the dependent variable\n",
    "Y_train = train_data['Y']\n",
    "\n",
    "# Fit the OLS regression model\n",
    "ols_model_X = sm.OLS(Y_train, X_train)\n",
    "ols_results_X = ols_model_X.fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(ols_results_X.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13147a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression Results for k = 1:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                    0.2121\n",
      "Date:                Fri, 15 Mar 2024   Prob (F-statistic):              0.645\n",
      "Time:                        00:27:12   Log-Likelihood:                -1383.5\n",
      "No. Observations:                 500   AIC:                             2771.\n",
      "Df Residuals:                     498   BIC:                             2779.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0318      0.173      5.980      0.000       0.693       1.371\n",
      "x1             0.0338      0.073      0.461      0.645      -0.110       0.178\n",
      "==============================================================================\n",
      "Omnibus:                        0.435   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.805   Jarque-Bera (JB):                0.547\n",
      "Skew:                           0.007   Prob(JB):                        0.761\n",
      "Kurtosis:                       2.839   Cond. No.                         2.35\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "OLS Regression Results for k = 5:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.219\n",
      "Model:                            OLS   Adj. R-squared:                  0.212\n",
      "Method:                 Least Squares   F-statistic:                     27.78\n",
      "Date:                Fri, 15 Mar 2024   Prob (F-statistic):           8.15e-25\n",
      "Time:                        00:27:12   Log-Likelihood:                -1321.7\n",
      "No. Observations:                 500   AIC:                             2655.\n",
      "Df Residuals:                     494   BIC:                             2681.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0173      0.154      6.606      0.000       0.715       1.320\n",
      "x1             0.0465      0.065      0.713      0.476      -0.082       0.175\n",
      "x2             0.0801      0.068      1.172      0.242      -0.054       0.214\n",
      "x3            -0.4423      0.073     -6.089      0.000      -0.585      -0.300\n",
      "x4             0.0759      0.078      0.973      0.331      -0.077       0.229\n",
      "x5            -0.8664      0.085    -10.146      0.000      -1.034      -0.699\n",
      "==============================================================================\n",
      "Omnibus:                        0.023   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.989   Jarque-Bera (JB):                0.051\n",
      "Skew:                           0.016   Prob(JB):                        0.975\n",
      "Kurtosis:                       2.963   Cond. No.                         2.40\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "OLS Regression Results for k = 10:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.501\n",
      "Model:                            OLS   Adj. R-squared:                  0.490\n",
      "Method:                 Least Squares   F-statistic:                     49.03\n",
      "Date:                Fri, 15 Mar 2024   Prob (F-statistic):           1.79e-67\n",
      "Time:                        00:27:13   Log-Likelihood:                -1210.0\n",
      "No. Observations:                 500   AIC:                             2442.\n",
      "Df Residuals:                     489   BIC:                             2488.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9625      0.124      7.753      0.000       0.719       1.206\n",
      "x1             0.0529      0.052      1.009      0.314      -0.050       0.156\n",
      "x2             0.0544      0.055      0.989      0.323      -0.054       0.162\n",
      "x3            -0.4352      0.059     -7.428      0.000      -0.550      -0.320\n",
      "x4             0.0851      0.063      1.355      0.176      -0.038       0.209\n",
      "x5            -0.8382      0.069    -12.185      0.000      -0.973      -0.703\n",
      "x6             0.6818      0.073      9.294      0.000       0.538       0.826\n",
      "x7            -0.4537      0.076     -5.968      0.000      -0.603      -0.304\n",
      "x8             0.6988      0.080      8.747      0.000       0.542       0.856\n",
      "x9            -0.4777      0.081     -5.888      0.000      -0.637      -0.318\n",
      "x10           -0.6213      0.085     -7.316      0.000      -0.788      -0.454\n",
      "==============================================================================\n",
      "Omnibus:                        0.129   Durbin-Watson:                   1.966\n",
      "Prob(Omnibus):                  0.938   Jarque-Bera (JB):                0.228\n",
      "Skew:                          -0.014   Prob(JB):                        0.892\n",
      "Kurtosis:                       2.899   Cond. No.                         2.42\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Extract the principal component scores\n",
    "Z_train = principal_component_scores[:500]\n",
    "\n",
    "# Fit the OLS regression models for different values of k\n",
    "for k in [1, 5, 10]:\n",
    "    # Select the first k principal components\n",
    "    Z_k = Z_train[:, :k]\n",
    "\n",
    "    # Add a constant to the principal component scores\n",
    "    Z_k = sm.add_constant(Z_k)\n",
    "\n",
    "    # Fit the OLS regression model\n",
    "    ols_model_Z = sm.OLS(Y_train, Z_k)\n",
    "    ols_results_Z = ols_model_Z.fit()\n",
    "\n",
    "    # Print the summary of the regression results\n",
    "    print(f\"OLS Regression Results for k = {k}:\")\n",
    "    print(ols_results_Z.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2f50d",
   "metadata": {},
   "source": [
    "d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "597e0e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Squared Prediction Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>4.334077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>15.006058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>12.924167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>8.454789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Mean Squared Prediction Error\n",
       "0  Model 1                       4.334077\n",
       "1  Model 2                      15.006058\n",
       "2  Model 3                      12.924167\n",
       "3  Model 4                       8.454789"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the independent variables for the test sample\n",
    "X_test = sm.add_constant(test_data.drop(columns=['Y']))\n",
    "\n",
    "# Define the dependent variable for the test sample\n",
    "Y_test = test_data['Y']\n",
    "\n",
    "# Initialize lists to store mean squared prediction errors\n",
    "mse_results = []\n",
    "\n",
    "# Predictions using the model with X1, ..., X50\n",
    "Y_pred_X = ols_results_X.predict(X_test)\n",
    "mse_X = np.mean((Y_test - Y_pred_X) ** 2)\n",
    "mse_results.append(mse_X)\n",
    "\n",
    "# Extract the principal component scores\n",
    "Z_train = principal_component_scores[:500]\n",
    "Z_test = principal_component_scores[-500:]\n",
    "\n",
    "# Predictions using the models with Z1*, ..., Zk* for k = 1, 5, 10\n",
    "for k in [1, 5, 10]:\n",
    "    \n",
    "    # Select the first k principal components\n",
    "    Z_k = Z_train[:, :k]\n",
    "\n",
    "    # Add a constant to the principal component scores\n",
    "    Z_k = sm.add_constant(Z_k)\n",
    "\n",
    "    # Fit the OLS regression model\n",
    "    ols_model_Z = sm.OLS(Y_train, Z_k)\n",
    "    ols_results_Z = ols_model_Z.fit()\n",
    "    \n",
    "    # Select the first k principal components for the test sample\n",
    "    Z_k_test = Z_test[:, :k]\n",
    "\n",
    "    # Add a constant to the principal component scores for the test sample\n",
    "    Z_k_test = sm.add_constant(Z_k_test)\n",
    "\n",
    "    # Predict Y using the model with Z1*, ..., Zk*\n",
    "    Y_pred_Z = ols_results_Z.predict(Z_k_test)\n",
    "    mse_Z = np.mean((Y_test - Y_pred_Z) ** 2)\n",
    "    mse_results.append(mse_Z)\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Append results for each model to the list\n",
    "for i, mse in enumerate(mse_results):\n",
    "    model_name = f\"Model {i + 1}\"\n",
    "    results_list.append({'Model': model_name, 'Mean Squared Prediction Error': mse})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc90e8d",
   "metadata": {},
   "source": [
    "e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0612cd",
   "metadata": {},
   "source": [
    "Looking at the table, we can see that the MSPE (Mean Squared Prediction Error) is generally lower in the last column (Ntr = 500) compared to the first column (Ntr = 75) for all the methods listed. This means that the prediction performance is better when the training size (Ntr) is larger.\n",
    "\n",
    "There are a couple of possible reasons for this. First, with a larger training size, the model has more data to learn from and can capture the underlying relationships between the variables more accurately. This leads to better predictions on unseen data.\n",
    "\n",
    "Second, with a smaller training size, the model is more likely to overfit the training data. Overfitting occurs when the model learns the idiosyncrasies of the training data too well, and it is not able to generalize well to unseen data. This can lead to higher MSPE on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad055dd",
   "metadata": {},
   "source": [
    "Generally, for both Ntr values (75 and 500), MSPE tends to decrease as the PCA level increases (using more principal components in model increases the model performance). Since the true data generating process is affected by al X's (explanatory variables), introducing more principal components increase the model performance to a certain degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc73b5",
   "metadata": {},
   "source": [
    "Another observation is that MSPE does not decrease much for models with PCA as training size increases, while the MSPE of OLS model without PCA decreases dramatically. PCA identifies and retains features based on the explained variance. There's a possibility that some informative features, though not contributing the most significant variance, might still be crucial for accurate predictions and we exclude this features in models with PCA. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
